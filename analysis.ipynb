{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","collapsed_sections":["TJC7m-lk80xJ","57dkLPuH9zhW"],"authorship_tag":"ABX9TyPu5uVDmiBqyj5K3XW1ZWqr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"yObSmaTbcOBU"}},{"cell_type":"markdown","source":["# Set-up"],"metadata":{"id":"TJC7m-lk80xJ"}},{"cell_type":"code","source":["# https://github.com/jayadevbhaskaran/gendered-sentiment\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')  # Upload github files to your drive — this method is persistent.\n","project_path = '/content/gdrive/My Drive/Colab Notebooks/nlpproject' # Replace 'YourProjectFolder' with your actual project folder name\n","\n","\n","\"\"\"\n","# Create new directory, downloads the GloVe 6B dataset, rename uppercase like \"B\" to'b', and unzip all files.\n","!mkdir -p \"{project_path}/glove.6b\"  # Create a new directory named 'glove.6b' within your project folder to store GloVe embeddings\n","!wget http://nlp.stanford.edu/data/glove.6B.zip -O \"{project_path}/glove.6b.zip\"  # Downloads the GloVe 6B dataset and saves it as 'glove.6b.zip'\n","!unzip \"{project_path}/glove.6b.zip\" -d \"{project_path}/glove.6b\"  # Unzip the downloaded GloVe embeddings zip file into the 'glove.6b' directory\n","!rename 's/6B/6b/' data/glove.6b/glove.6B.*\n","\n","!ls \"{project_path}/glove.6b\"  # List the contents of the 'glove.6b' directory to verify the extractio\n","\"\"\""],"metadata":{"id":"BF-Q2QJM9T3E","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1732556389057,"user_tz":300,"elapsed":28453,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"0d1950af-1f52-49a1-d37f-989e80224540"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n# Create new directory, downloads the GloVe 6B dataset, rename uppercase like \"B\" to\\'b\\', and unzip all files.\\n!mkdir -p \"{project_path}/glove.6b\"  # Create a new directory named \\'glove.6b\\' within your project folder to store GloVe embeddings\\n!wget http://nlp.stanford.edu/data/glove.6B.zip -O \"{project_path}/glove.6b.zip\"  # Downloads the GloVe 6B dataset and saves it as \\'glove.6b.zip\\'\\n!unzip \"{project_path}/glove.6b.zip\" -d \"{project_path}/glove.6b\"  # Unzip the downloaded GloVe embeddings zip file into the \\'glove.6b\\' directory\\n!rename \\'s/6B/6b/\\' data/glove.6b/glove.6B.*\\n\\n!ls \"{project_path}/glove.6b\"  # List the contents of the \\'glove.6b\\' directory to verify the extractio\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import wandb\n","wandb.login()\n","wandb.init(project=\"nlpcapstone\", entity=\"mariamabdullahedu-student\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"Kqy8Hy88VH98","executionInfo":{"status":"ok","timestamp":1732549348455,"user_tz":300,"elapsed":13209,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"7df4ae00-01d5-4f0d-988f-9b36d0cd46c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariamabdullahedu\u001b[0m (\u001b[33mmariamabdullahedu-student\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241125_154226-x28s0225</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/mariamabdullahedu-student/nlpcapstone/runs/x28s0225' target=\"_blank\">apricot-shape-4</a></strong> to <a href='https://wandb.ai/mariamabdullahedu-student/nlpcapstone' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/mariamabdullahedu-student/nlpcapstone' target=\"_blank\">https://wandb.ai/mariamabdullahedu-student/nlpcapstone</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/mariamabdullahedu-student/nlpcapstone/runs/x28s0225' target=\"_blank\">https://wandb.ai/mariamabdullahedu-student/nlpcapstone/runs/x28s0225</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mariamabdullahedu-student/nlpcapstone/runs/x28s0225?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x78716857fca0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Actual Code"],"metadata":{"id":"57dkLPuH9zhW"}},{"cell_type":"code","source":["%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/nlpproject"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NyjKmw6GOLB","executionInfo":{"status":"ok","timestamp":1732556786695,"user_tz":300,"elapsed":2,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"2b718842-54a4-490f-cf29-95ee7ff16f47"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Colab Notebooks/nlpproject\n"]}]},{"cell_type":"code","source":["!python3 src/baseline.py"],"metadata":{"id":"220ljP8VlPpJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732549367600,"user_tz":300,"elapsed":12801,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"d821f1e0-bef3-40b0-d3bf-e60d63a2635d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8268348623853211\n"]}]},{"cell_type":"code","source":["!python3 src/bilstm.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NGRO4XI01Tu","executionInfo":{"status":"ok","timestamp":1732549470614,"user_tz":300,"elapsed":103016,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"cac4c839-ffbc-4134-ffe1-ad974e99a2ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-25 15:42:48.499487: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-25 15:42:48.516971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-25 15:42:48.537682: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-25 15:42:48.543996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-25 15:42:48.558822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-25 15:42:49.640652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Found 14653 unique tokens.\n","323 words missing from GloVe vocabulary\n","/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n","2024-11-25 15:43:20.810147: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-11-25 15:43:20.813024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38554 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n","\u001b[1mModel: \"sequential\"\u001b[0m\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[94mEmbedding\u001b[0m)                │ ?                           │       \u001b[32m4,396,200\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional (\u001b[94mBidirectional\u001b[0m)        │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[94mDropout\u001b[0m)                    │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[94mDense\u001b[0m)                        │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","\u001b[1m Total params: \u001b[0m\u001b[32m4,396,200\u001b[0m (16.77 MB)\n","\u001b[1m Trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n","\u001b[1m Non-trainable params: \u001b[0m\u001b[32m4,396,200\u001b[0m (16.77 MB)\n","None\n","Epoch 1/3\n","2024-11-25 15:43:25.322310: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n","\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.8153 - loss: 0.4026 - val_accuracy: 0.8245 - val_loss: 0.3667\n","Epoch 2/3\n","\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8982 - loss: 0.2466 - val_accuracy: 0.8463 - val_loss: 0.3545\n","Epoch 3/3\n","\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.1770 - val_accuracy: 0.8498 - val_loss: 0.4010\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n","0.8497706422018348\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3n_sRXNyHlCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 src/albert_finetune.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15bRTDTr-foF","outputId":"331d7fbd-3adc-4492-a7c6-48e0e5233b1c","executionInfo":{"status":"ok","timestamp":1732398506162,"user_tz":300,"elapsed":983039,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-11-23 21:32:13.151863: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-11-23 21:32:13.168060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-11-23 21:32:13.189902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-11-23 21:32:13.196367: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-11-23 21:32:13.212146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-11-23 21:32:14.384607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 154kB/s]\n","spiece.model: 100% 760k/760k [00:00<00:00, 11.4MB/s]\n","tokenizer.json: 100% 1.31M/1.31M [00:00<00:00, 27.3MB/s]\n","config.json: 100% 684/684 [00:00<00:00, 6.64MB/s]\n","model.safetensors: 100% 47.4M/47.4M [00:00<00:00, 160MB/s]\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/content/gdrive/My Drive/Colab Notebooks/nlpproject/src/albert_finetune.py:76: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariamabdullahedu\u001b[0m (\u001b[33mmariamabdullahedu-student\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/gdrive/My Drive/Colab Notebooks/nlpproject/wandb/run-20241123_213231-esizpyxy\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/albert_output\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mariamabdullahedu-student/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mariamabdullahedu-student/huggingface/runs/esizpyxy\u001b[0m\n","{'loss': 0.6573, 'grad_norm': 34.73806381225586, 'learning_rate': 1.9604070158767868e-05, 'epoch': 0.06}\n","{'loss': 0.4837, 'grad_norm': 12.218064308166504, 'learning_rate': 1.9208140317535734e-05, 'epoch': 0.12}\n","{'loss': 0.454, 'grad_norm': 7.555488109588623, 'learning_rate': 1.88122104763036e-05, 'epoch': 0.18}\n","{'loss': 0.424, 'grad_norm': 5.062306880950928, 'learning_rate': 1.8416280635071467e-05, 'epoch': 0.24}\n","{'loss': 0.454, 'grad_norm': 6.682765483856201, 'learning_rate': 1.8020350793839333e-05, 'epoch': 0.3}\n","{'loss': 0.3937, 'grad_norm': 6.147634029388428, 'learning_rate': 1.76244209526072e-05, 'epoch': 0.36}\n","{'loss': 0.4017, 'grad_norm': 4054.422607421875, 'learning_rate': 1.7228491111375066e-05, 'epoch': 0.42}\n","{'loss': 0.3835, 'grad_norm': 19.252567291259766, 'learning_rate': 1.6832561270142932e-05, 'epoch': 0.48}\n","{'loss': 0.3953, 'grad_norm': 2.2773241996765137, 'learning_rate': 1.64366314289108e-05, 'epoch': 0.53}\n","{'loss': 0.3756, 'grad_norm': 12.63744068145752, 'learning_rate': 1.6040701587678665e-05, 'epoch': 0.59}\n","{'loss': 0.3849, 'grad_norm': 35.37383270263672, 'learning_rate': 1.564477174644653e-05, 'epoch': 0.65}\n","{'loss': 0.3861, 'grad_norm': 9.407733917236328, 'learning_rate': 1.5248841905214398e-05, 'epoch': 0.71}\n","{'loss': 0.3747, 'grad_norm': 61.706756591796875, 'learning_rate': 1.4852912063982263e-05, 'epoch': 0.77}\n","{'loss': 0.3753, 'grad_norm': 8.33358383178711, 'learning_rate': 1.4456982222750129e-05, 'epoch': 0.83}\n","{'loss': 0.3769, 'grad_norm': 26.793195724487305, 'learning_rate': 1.4061052381517997e-05, 'epoch': 0.89}\n","{'loss': 0.3424, 'grad_norm': 55.39572525024414, 'learning_rate': 1.3665122540285862e-05, 'epoch': 0.95}\n"," 33% 8419/25257 [05:16<10:32, 26.61it/s]\n","  0% 0/109 [00:00<?, ?it/s]\u001b[A\n","  9% 10/109 [00:00<00:01, 91.52it/s]\u001b[A\n"," 18% 20/109 [00:00<00:01, 87.31it/s]\u001b[A\n"," 27% 29/109 [00:00<00:00, 85.98it/s]\u001b[A\n"," 35% 38/109 [00:00<00:00, 85.05it/s]\u001b[A\n"," 43% 47/109 [00:00<00:00, 83.78it/s]\u001b[A\n"," 51% 56/109 [00:00<00:00, 83.63it/s]\u001b[A\n"," 60% 65/109 [00:00<00:00, 78.75it/s]\u001b[A\n"," 67% 73/109 [00:00<00:00, 77.20it/s]\u001b[A\n"," 75% 82/109 [00:01<00:00, 79.16it/s]\u001b[A\n"," 83% 91/109 [00:01<00:00, 80.65it/s]\u001b[A\n"," 92% 100/109 [00:01<00:00, 81.31it/s]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 0.41133350133895874, 'eval_accuracy': 0.8337155963302753, 'eval_runtime': 1.3591, 'eval_samples_per_second': 641.602, 'eval_steps_per_second': 80.2, 'epoch': 1.0}\n"," 33% 8419/25257 [05:17<10:32, 26.61it/s]\n","100% 109/109 [00:01<00:00, 82.23it/s]\u001b[A\n","{'loss': 0.3502, 'grad_norm': 29.286191940307617, 'learning_rate': 1.3269192699053728e-05, 'epoch': 1.01}\n","{'loss': 0.3276, 'grad_norm': 25.01337242126465, 'learning_rate': 1.2873262857821596e-05, 'epoch': 1.07}\n","{'loss': 0.3156, 'grad_norm': 0.6504628658294678, 'learning_rate': 1.247733301658946e-05, 'epoch': 1.13}\n","{'loss': 0.3336, 'grad_norm': 4.556275367736816, 'learning_rate': 1.2081403175357327e-05, 'epoch': 1.19}\n","{'loss': 0.3227, 'grad_norm': 23.549766540527344, 'learning_rate': 1.1685473334125195e-05, 'epoch': 1.25}\n","{'loss': 0.3309, 'grad_norm': 73.32935333251953, 'learning_rate': 1.128954349289306e-05, 'epoch': 1.31}\n","{'loss': 0.3135, 'grad_norm': 4.26780891418457, 'learning_rate': 1.0893613651660926e-05, 'epoch': 1.37}\n","{'loss': 0.2779, 'grad_norm': 16.21828842163086, 'learning_rate': 1.0497683810428794e-05, 'epoch': 1.43}\n","{'loss': 0.3341, 'grad_norm': 43.44031524658203, 'learning_rate': 1.0101753969196659e-05, 'epoch': 1.48}\n","{'loss': 0.2975, 'grad_norm': 74.33539581298828, 'learning_rate': 9.705824127964525e-06, 'epoch': 1.54}\n","{'loss': 0.2923, 'grad_norm': 74.5454330444336, 'learning_rate': 9.309894286732392e-06, 'epoch': 1.6}\n","{'loss': 0.3028, 'grad_norm': 0.4209847152233124, 'learning_rate': 8.913964445500258e-06, 'epoch': 1.66}\n","{'loss': 0.283, 'grad_norm': 0.24739518761634827, 'learning_rate': 8.518034604268124e-06, 'epoch': 1.72}\n","{'loss': 0.2907, 'grad_norm': 104.5452880859375, 'learning_rate': 8.12210476303599e-06, 'epoch': 1.78}\n","{'loss': 0.2832, 'grad_norm': 38.48925018310547, 'learning_rate': 7.726174921803857e-06, 'epoch': 1.84}\n","{'loss': 0.2935, 'grad_norm': 82.73096466064453, 'learning_rate': 7.330245080571723e-06, 'epoch': 1.9}\n","{'loss': 0.2945, 'grad_norm': 36.53180694580078, 'learning_rate': 6.93431523933959e-06, 'epoch': 1.96}\n"," 67% 16837/25257 [10:32<05:14, 26.75it/s]\n","  0% 0/109 [00:00<?, ?it/s]\u001b[A\n","  9% 10/109 [00:00<00:01, 90.02it/s]\u001b[A\n"," 18% 20/109 [00:00<00:01, 86.77it/s]\u001b[A\n"," 27% 29/109 [00:00<00:00, 84.48it/s]\u001b[A\n"," 35% 38/109 [00:00<00:00, 83.77it/s]\u001b[A\n"," 43% 47/109 [00:00<00:00, 83.34it/s]\u001b[A\n"," 51% 56/109 [00:00<00:00, 82.15it/s]\u001b[A\n"," 60% 65/109 [00:00<00:00, 81.90it/s]\u001b[A\n"," 68% 74/109 [00:00<00:00, 82.19it/s]\u001b[A\n"," 76% 83/109 [00:00<00:00, 83.04it/s]\u001b[A\n"," 84% 92/109 [00:01<00:00, 83.47it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.5975144505500793, 'eval_accuracy': 0.8704128440366973, 'eval_runtime': 1.3205, 'eval_samples_per_second': 660.356, 'eval_steps_per_second': 82.544, 'epoch': 2.0}\n"," 67% 16838/25257 [10:33<05:14, 26.75it/s]\n","100% 109/109 [00:01<00:00, 83.47it/s]\u001b[A\n","{'loss': 0.2618, 'grad_norm': 0.06620534509420395, 'learning_rate': 6.538385398107456e-06, 'epoch': 2.02}\n","{'loss': 0.2569, 'grad_norm': 0.1487497091293335, 'learning_rate': 6.1424555568753215e-06, 'epoch': 2.08}\n","{'loss': 0.2329, 'grad_norm': 8.734052658081055, 'learning_rate': 5.746525715643189e-06, 'epoch': 2.14}\n","{'loss': 0.224, 'grad_norm': 0.6736640930175781, 'learning_rate': 5.350595874411055e-06, 'epoch': 2.2}\n","{'loss': 0.2553, 'grad_norm': 142.7067413330078, 'learning_rate': 4.9546660331789206e-06, 'epoch': 2.26}\n","{'loss': 0.233, 'grad_norm': 140.01974487304688, 'learning_rate': 4.558736191946788e-06, 'epoch': 2.32}\n","{'loss': 0.2486, 'grad_norm': 1.8962733745574951, 'learning_rate': 4.162806350714654e-06, 'epoch': 2.38}\n","{'loss': 0.2379, 'grad_norm': 7.086030006408691, 'learning_rate': 3.76687650948252e-06, 'epoch': 2.43}\n","{'loss': 0.2248, 'grad_norm': 53.24538803100586, 'learning_rate': 3.370946668250386e-06, 'epoch': 2.49}\n","{'loss': 0.2359, 'grad_norm': 159.58018493652344, 'learning_rate': 2.9750168270182528e-06, 'epoch': 2.55}\n","{'loss': 0.2432, 'grad_norm': 0.03570680320262909, 'learning_rate': 2.579086985786119e-06, 'epoch': 2.61}\n","{'loss': 0.2196, 'grad_norm': 0.12805211544036865, 'learning_rate': 2.183157144553985e-06, 'epoch': 2.67}\n","{'loss': 0.2219, 'grad_norm': 0.15695439279079437, 'learning_rate': 1.7872273033218516e-06, 'epoch': 2.73}\n","{'loss': 0.2287, 'grad_norm': 40.062679290771484, 'learning_rate': 1.391297462089718e-06, 'epoch': 2.79}\n","{'loss': 0.1963, 'grad_norm': 0.791317343711853, 'learning_rate': 9.953676208575841e-07, 'epoch': 2.85}\n","{'loss': 0.2054, 'grad_norm': 0.33526942133903503, 'learning_rate': 5.994377796254505e-07, 'epoch': 2.91}\n","{'loss': 0.2062, 'grad_norm': 0.07253158092498779, 'learning_rate': 2.0350793839331672e-07, 'epoch': 2.97}\n","100% 25255/25257 [15:46<00:00, 26.58it/s]\n","  0% 0/109 [00:00<?, ?it/s]\u001b[A\n","  9% 10/109 [00:00<00:01, 92.46it/s]\u001b[A\n"," 18% 20/109 [00:00<00:01, 86.72it/s]\u001b[A\n"," 27% 29/109 [00:00<00:00, 84.75it/s]\u001b[A\n"," 35% 38/109 [00:00<00:00, 83.25it/s]\u001b[A\n"," 43% 47/109 [00:00<00:00, 82.88it/s]\u001b[A\n"," 51% 56/109 [00:00<00:00, 82.46it/s]\u001b[A\n"," 60% 65/109 [00:00<00:00, 82.86it/s]\u001b[A\n"," 68% 74/109 [00:00<00:00, 82.86it/s]\u001b[A\n"," 76% 83/109 [00:00<00:00, 83.73it/s]\u001b[A\n"," 84% 92/109 [00:01<00:00, 84.60it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.6241990327835083, 'eval_accuracy': 0.8738532110091743, 'eval_runtime': 1.3077, 'eval_samples_per_second': 666.822, 'eval_steps_per_second': 83.353, 'epoch': 3.0}\n","100% 25257/25257 [15:48<00:00, 26.58it/s]\n","100% 109/109 [00:01<00:00, 84.96it/s]\u001b[A\n","{'train_runtime': 949.2365, 'train_samples_per_second': 212.852, 'train_steps_per_second': 26.608, 'train_loss': 0.3161485056301881, 'epoch': 3.0}\n","100% 25257/25257 [15:48<00:00, 26.63it/s]\n","100% 109/109 [00:01<00:00, 85.63it/s]\n","Validation accuracy: 0.8739\n","100% 109/109 [00:01<00:00, 84.23it/s]\n","Predictions saved to /content/gdrive/My Drive/Colab Notebooks/nlpproject/runs/gender/test_results.tsv\n"]}]},{"cell_type":"markdown","source":["# Analysis"],"metadata":{"id":"a9gzO_i0Sy-y"}},{"cell_type":"code","source":["!python3 src/analysis.py"],"metadata":{"id":"QEO3iINV_NJA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732551385196,"user_tz":300,"elapsed":10154,"user":{"displayName":"Mariam Abdullah","userId":"12442860999654857065"}},"outputId":"f8f2e2fd-bd5f-460c-b967-e0356e994c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[-5.906212425825358, 7.501185188242566e-09, 0.0345668387793015], [-3.1718725905444343, 0.0016317204812352577, 0.041926803486043274], [1.1685933255210845, 0.24326524140572028, -0.041486174]]\n","\n","\n","Male:  1182 0.5346869712351946\n","Female:  601 0.5990016638935108\n","\n","\n","Profession mean_sentiment female-male\n","doctor 0.5510329 0.19298714\n","tailor 0.5010188 0.07261896\n","baker 0.5839361 0.03975624\n","secretary 0.55057305 -0.19687605\n","professor 0.533852 -0.033409\n","scientist 0.56870306 0.13333184\n","writer 0.55543166 0.090203464\n","teacher 0.4526431 -0.31191087\n","truck driver 0.46130982 -0.14167768\n","pilot 0.3316312 -0.17408599\n","lawyer 0.5067767 0.09003383\n","flight attendant 0.59213984 0.0018737316\n","nurse 0.4182628 -0.13762197\n","chef 0.5008215 0.10030687\n","soldier 0.4912507 -0.31595385\n","dancer 0.52163684 -0.53959006\n","gym trainer 0.5522043 0.09706324\n","mechanic 0.42195368 0.05451402\n","clerk 0.45122474 0.19907776\n","bartender 0.62482184 -0.050364792\n","CONTROL 0.9964181 0.0\n","\n","\n","noun female-male\n","He -0.060819007\n","This boy 0.004403785\n","This man -0.0128867505\n","My father -0.10236033\n","My son 0.05642703\n","My grandfather 0.08378642\n","My grandson 0.037085004\n","My uncle -0.19968839\n","My nephew 0.16335736\n","My brother -0.1479948\n","My boyfriend -0.19267371\n","My husband -0.2200779\n","The groom -0.30383518\n","This gentleman 0.13504955\n","The male candidate -0.071301684\n","Sir, you are 0.06789161\n","Dad -0.24147129\n","Grandpa 0.10277654\n","This widower 0.2465401\n","This bachelor -0.1739318\n","spinster-bachelor:  -0.17393169 0.2613086718664125\n"]}]},{"cell_type":"markdown","source":["### Sentiment Scores\n","\n","| **Metric**              | **BERT/Kina Run** | **ALBERT/Mariam Run** | **Diffs/Comment**         |\n","|--------------------------|-------------------|------------------------|---------------------------|\n","| Male Sentiment           | 0.535            | 0.535                 | Identical.               |\n","| Female Sentiment         | 0.599            | 0.599                 | Identical.               |\n","| Female-Male Difference   | +0.064           | +0.064                | Identical.               |\n","\n","---\n","\n","### Profession Analysis\n","\n","| **Profession**           | **BERT/Kina Run**         | **ALBERT/Mariam Run**      | **Diffs/Comment**                   |\n","|---------------------------|---------------------------|-----------------------------|-------------------------------------|\n","| Doctor                   | 0.524 (+0.050)           | 0.551 (+0.193)             | ALBERT shows higher female bias.   |\n","| Tailor                   | 0.526 (+0.153)           | 0.501 (+0.073)             | BER shows higher female bias.      |\n","| Secretary                | 0.587 (-0.123)           | 0.551 (-0.197)             | ALBERT shows greater male bias.    |\n","| Dancer                   | 0.476 (-0.450)           | 0.522 (-0.540)             | ALBERT shows more male bias.       |\n","| Chef                     | 0.478 (+0.252)           | 0.501 (+0.100)             | BER shows higher female bias.      |\n","| Nurse                    | 0.429 (-0.058)           | 0.418 (-0.138)             | ALBERT shows more male bias.       |\n","\n","---\n","\n","### Control Sentence Evaluation\n","\n","| **Metric**               | **BERT/Kina Run** | **ALBERT/Mariam Run** | **Diffs/Comment**                   |\n","|---------------------------|-------------------|------------------------|-------------------------------------|\n","| Control Mean Sentiment    | 0.999            | 0.996                 | Slightly lower mean for ALBERT.    |\n","| Control Female-Male Diff. | 0.0              | 0.0                   | Identical.                         |\n","\n","---\n","### Noun Analysis\n","\n","| **Noun**                | **BERT/Kina Run**         | **ALBERT/Mariam Run**       | **Diffs/Comment**                |\n","|--------------------------|---------------------------|-----------------------------|----------------------------------|\n","| He                      | +0.0037                  | -0.0608                    | ALBERT shows more male bias.    |\n","| This man                | -0.1470                  | -0.0129                    | ALBERT shows less male bias.    |\n","| My father               | -0.1817                  | -0.1024                    | ALBERT reduces male bias.       |\n","| This widower            | +0.396                   | +0.247                     | BER shows higher female bias.   |\n","\n","---\n","\n","### Spinster vs. Bachelor\n","\n","| **Comparison**             | **BERT/Kina Run**            | **ALBERT/Mariam Run**        | **Diffs/Comment**                  |\n","|-----------------------------|-----------------------------|-----------------------------|------------------------------------|\n","| Spinster vs. Bachelor       | -0.101, p = 0.538          | -0.174, p = 0.261          | ALBERT shows stronger male bias, though insignificant. |\n","\n","###Takeaways:\n","\n","1. **Male vs. Female Sentiment**: Scores are identical for both models, with females having slightly higher mean sentiment (+0.064).\n","\n","2. **Profession Analysis**:\n","   - ALBERT demonstrates higher female bias for professions like \"doctor\" and \"scientist.\"\n","   - BERT shows stronger female bias in roles like \"chef\" and \"tailor.\"\n","   - ALBERT displays greater male bias for roles such as \"dancer\" and \"secretary.\"\n","\n","3. **Control Sentences**:\n","   - Both models have similar results for control sentences, with identical female-male differences of 0.0. ALBERT has a slightly lower mean sentiment.\n","\n","4. **Noun Analysis**:\n","   - ALBERT reduces male bias for nouns like \"This man\" and \"My father\" compared to BERT.\n","   - BERT exhibits higher female bias for nouns like \"This widower.\"\n","\n","5. **Spinster vs. Bachelor**:\n","   - ALBERT shows a stronger male bias for \"bachelor\" compared to \"spinster\" (difference = -0.174) than BERT (difference = -0.101), though both results remain statistically insignificant.\n","\n","Overall, ALBERT tends to balance male-female biases in some cases but amplifies them in others, highlighting nuanced differences between the two models."],"metadata":{"id":"FNkwd7vCJvC7"}}]}