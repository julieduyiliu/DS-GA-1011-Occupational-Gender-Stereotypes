{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdzv_N5-E3MC",
    "outputId": "32c9a979-dc0d-46a9-bbd4-a6487c57311b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LMSI1h9F1eM",
    "outputId": "f2186a05-830d-44cb-9895-a8abb2a22938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: __MACOSX/._data         \n",
      "  inflating: data/gender_corpus.tsv  \n",
      "  inflating: __MACOSX/data/._gender_corpus.tsv  \n",
      "  inflating: data/train.tsv          \n",
      "  inflating: __MACOSX/data/._train.tsv  \n",
      "  inflating: data/plot_data.csv      \n",
      "  inflating: __MACOSX/data/._plot_data.csv  \n",
      "  inflating: data/dev.tsv            \n",
      "  inflating: __MACOSX/data/._dev.tsv  \n",
      "  inflating: data/gender.tsv         \n",
      "  inflating: __MACOSX/data/._gender.tsv  \n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTa4-PReGJuh",
    "outputId": "6597e893-689e-47a6-d5cb-a288bcab7c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  src.zip\n",
      "   creating: src/\n",
      "  inflating: __MACOSX/._src          \n",
      "  inflating: src/config.py           \n",
      "  inflating: __MACOSX/src/._config.py  \n",
      "  inflating: src/analysis.py         \n",
      "  inflating: __MACOSX/src/._analysis.py  \n",
      "  inflating: src/baseline.py         \n",
      "  inflating: __MACOSX/src/._baseline.py  \n",
      "  inflating: src/generate_corpus.py  \n",
      "  inflating: __MACOSX/src/._generate_corpus.py  \n",
      "  inflating: src/utils.py            \n",
      "  inflating: __MACOSX/src/._utils.py  \n",
      "  inflating: src/bilstm.py           \n",
      "  inflating: __MACOSX/src/._bilstm.py  \n"
     ]
    }
   ],
   "source": [
    "!unzip src.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JwS41iNG1Ug",
    "outputId": "18cc7e8e-edd8-4664-8892-54607dc1f55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  runs.zip\n",
      "   creating: runs/\n",
      "  inflating: __MACOSX/._runs         \n",
      "   creating: runs/gender/\n",
      "  inflating: __MACOSX/runs/._gender  \n",
      "  inflating: runs/results.txt        \n",
      "  inflating: __MACOSX/runs/._results.txt  \n",
      "  inflating: runs/logreg.txt         \n",
      "  inflating: __MACOSX/runs/._logreg.txt  \n",
      "  inflating: runs/plot.png           \n",
      "  inflating: __MACOSX/runs/._plot.png  \n",
      "  inflating: runs/lstm.txt           \n",
      "  inflating: __MACOSX/runs/._lstm.txt  \n",
      "  inflating: runs/lstm.h5            \n",
      "  inflating: __MACOSX/runs/._lstm.h5  \n",
      "  inflating: runs/gender/test_results.tsv  \n",
      "  inflating: __MACOSX/runs/gender/._test_results.tsv  \n",
      "  inflating: runs/gender/test.tsv    \n",
      "  inflating: __MACOSX/runs/gender/._test.tsv  \n"
     ]
    }
   ],
   "source": [
    "!unzip runs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBM0xB99SUFg",
    "outputId": "f9259a1b-99d7-4a70-f72b-7724d3eb87d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-04 17:48:29--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2024-11-04 17:48:29--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2024-11-04 17:48:30--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘/content/data/glove.6b.zip’\n",
      "\n",
      "/content/data/glove 100%[===================>] 822.24M  5.06MB/s    in 2m 39s  \n",
      "\n",
      "2024-11-04 17:51:10 (5.17 MB/s) - ‘/content/data/glove.6b.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  /content/data/glove.6b.zip\n",
      "  inflating: /content/data/glove.6b/glove.6B.50d.txt  \n",
      "  inflating: /content/data/glove.6b/glove.6B.100d.txt  \n",
      "  inflating: /content/data/glove.6b/glove.6B.200d.txt  \n",
      "  inflating: /content/data/glove.6b/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/data/glove.6b\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip -O /content/data/glove.6b.zip\n",
    "!unzip /content/data/glove.6b.zip -d /content/data/glove.6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arOivSZsTzNs"
   },
   "outputs": [],
   "source": [
    "!mv /content/data/glove.6b/glove.6B.300d.txt /content/data/glove.6b/glove.6b.300d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6rA5Y-qFWSf",
    "outputId": "73300713-8f05-4b53-e662-7d3f1f454919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8268348623853211\n"
     ]
    }
   ],
   "source": [
    "!python3 src/baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P5yl55SJB86",
    "outputId": "88e1680b-6c03-4f65-ecb8-81aa754cea78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-04 18:19:16.906682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-04 18:19:16.926759: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-04 18:19:16.932714: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 18:19:16.946964: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 18:19:17.960508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Found 14653 unique tokens.\n",
      "323 words missing from GloVe vocabulary\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730744382.346234   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.405569   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.405890   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.407371   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.407618   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.407821   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.499279   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1730744382.499538   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-04 18:19:42.499654: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1730744382.499766   15769 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-04 18:19:42.499891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "\u001b[1mModel: \"sequential\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ embedding (\u001b[94mEmbedding\u001b[0m)                │ ?                           │       \u001b[32m4,396,200\u001b[0m │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ bidirectional (\u001b[94mBidirectional\u001b[0m)        │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)                    │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)                        │ ?                           │     \u001b[32m0\u001b[0m (unbuilt) │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m4,396,200\u001b[0m (16.77 MB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m4,396,200\u001b[0m (16.77 MB)\n",
      "None\n",
      "Epoch 1/3\n",
      "2024-11-04 18:19:45.619439: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8170 - loss: 0.4027 - val_accuracy: 0.8291 - val_loss: 0.3803\n",
      "Epoch 2/3\n",
      "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8982 - loss: 0.2490 - val_accuracy: 0.8211 - val_loss: 0.3926\n",
      "Epoch 3/3\n",
      "\u001b[1m2105/2105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9315 - loss: 0.1778 - val_accuracy: 0.8291 - val_loss: 0.4277\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "0.8291284403669725\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "!python3 src/bilstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl3xy1FWa3gT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the necessary directories\n",
    "os.makedirs(\"/content/runs/gender/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmGITCAAbjBF"
   },
   "outputs": [],
   "source": [
    "!ls /content/runs/gender/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAoXzk70F0oR",
    "outputId": "49028571-d4db-44db-c2ad-d6649d1170bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.906212430863586, 7.501184977414321e-09, 0.03456683929070509], [-6.920792485631636, 1.799571411271696e-11, 0.10090649259386736]]\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/src/analysis.py\", line 48, in <module>\n",
      "    m_list.append(item['_1'])\n",
      "KeyError: '_1'\n"
     ]
    }
   ],
   "source": [
    "!python3 src/analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7O9AnboJCQP",
    "outputId": "daeb4e68-5297-4ea2-8831-9564e4419ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: content/runs/ (stored 0%)\n",
      "updating: content/runs/gender/ (stored 0%)\n",
      "updating: content/runs/lstm.h5 (deflated 10%)\n",
      "updating: content/runs/.ipynb_checkpoints/ (stored 0%)\n",
      "updating: content/runs/results.txt (deflated 26%)\n",
      "updating: content/runs/logreg.txt (deflated 75%)\n",
      "updating: content/runs/lstm.txt (deflated 55%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r runs.zip /content/runs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS2jlhnDcq_m"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "vlSUV5DqcgVZ",
    "outputId": "f5ab5ce0-b478-41d7-cdba-aeabe1bb150c"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e8c5d0cc-ddc9-4231-aa46-f305c49935ab\", \"runs.zip\", 41412997)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('runs.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRV2oWafc8gU",
    "outputId": "a6057abc-7600-4577-ecef-3da21313cf8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/src/ (stored 0%)\n",
      "  adding: content/src/analysis.py (deflated 65%)\n",
      "  adding: content/src/utils.py (deflated 59%)\n",
      "  adding: content/src/config.py (deflated 65%)\n",
      "  adding: content/src/baseline.py (deflated 59%)\n",
      "  adding: content/src/bilstm.py (deflated 62%)\n",
      "  adding: content/src/__pycache__/ (stored 0%)\n",
      "  adding: content/src/__pycache__/utils.cpython-310.pyc (deflated 40%)\n",
      "  adding: content/src/__pycache__/config.cpython-310.pyc (deflated 41%)\n",
      "  adding: content/src/generate_corpus.py (deflated 58%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r src.zip /content/src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Jy02w1ZkdC5e",
    "outputId": "b7c26401-cbc2-45c4-e23b-c00c35c7d7f4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_122a06c8-5460-452c-94e2-7102fe67902c\", \"src.zip\", 17271)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('src.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFP3Ep3EeyX1",
    "outputId": "4ec39fdf-cec4-43ce-ac11-066ce8ae8d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-04 19:11:37.533071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-04 19:11:37.554804: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-04 19:11:37.561130: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 19:11:37.576629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 19:11:38.863609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 301kB/s]\n",
      "vocab.txt: 100% 232k/232k [00:00<00:00, 1.08MB/s]\n",
      "tokenizer.json: 100% 466k/466k [00:00<00:00, 2.12MB/s]\n",
      "config.json: 100% 570/570 [00:00<00:00, 4.22MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "model.safetensors: 100% 440M/440M [00:01<00:00, 243MB/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "{'loss': 0.3957, 'grad_norm': 0.46386995911598206, 'learning_rate': 1.9604070158767868e-05, 'epoch': 0.06}\n",
      "{'loss': 0.3519, 'grad_norm': 29.027267456054688, 'learning_rate': 1.9208140317535734e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3136, 'grad_norm': 3.814696788787842, 'learning_rate': 1.88122104763036e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3205, 'grad_norm': 3.3597922325134277, 'learning_rate': 1.8416280635071467e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2796, 'grad_norm': 76.8846435546875, 'learning_rate': 1.8020350793839333e-05, 'epoch': 0.3}\n",
      "{'loss': 0.2579, 'grad_norm': 0.28890883922576904, 'learning_rate': 1.76244209526072e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2614, 'grad_norm': 1.3250532150268555, 'learning_rate': 1.7228491111375066e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2605, 'grad_norm': 10.403717994689941, 'learning_rate': 1.6832561270142932e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2412, 'grad_norm': 2.2514238357543945, 'learning_rate': 1.64366314289108e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2313, 'grad_norm': 2.090273380279541, 'learning_rate': 1.6040701587678665e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2386, 'grad_norm': 17.968551635742188, 'learning_rate': 1.564477174644653e-05, 'epoch': 0.65}\n",
      "{'loss': 0.2438, 'grad_norm': 15.752456665039062, 'learning_rate': 1.5248841905214398e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2237, 'grad_norm': 21.833377838134766, 'learning_rate': 1.4852912063982263e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2335, 'grad_norm': 17.02798080444336, 'learning_rate': 1.4456982222750129e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2276, 'grad_norm': 36.39757537841797, 'learning_rate': 1.4061052381517997e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2045, 'grad_norm': 37.29602813720703, 'learning_rate': 1.3665122540285862e-05, 'epoch': 0.95}\n",
      " 33% 8419/25257 [19:37<35:46,  7.85it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 5/109 [00:00<00:02, 45.45it/s]\u001b[A\n",
      "  9% 10/109 [00:00<00:02, 38.97it/s]\u001b[A\n",
      " 13% 14/109 [00:00<00:02, 37.09it/s]\u001b[A\n",
      " 17% 18/109 [00:00<00:02, 36.24it/s]\u001b[A\n",
      " 20% 22/109 [00:00<00:02, 36.07it/s]\u001b[A\n",
      " 24% 26/109 [00:00<00:02, 35.97it/s]\u001b[A\n",
      " 28% 30/109 [00:00<00:02, 35.86it/s]\u001b[A\n",
      " 31% 34/109 [00:00<00:02, 35.64it/s]\u001b[A\n",
      " 35% 38/109 [00:01<00:01, 35.59it/s]\u001b[A\n",
      " 39% 42/109 [00:01<00:01, 35.71it/s]\u001b[A\n",
      " 42% 46/109 [00:01<00:01, 35.68it/s]\u001b[A\n",
      " 46% 50/109 [00:01<00:01, 35.57it/s]\u001b[A\n",
      " 50% 54/109 [00:01<00:01, 35.40it/s]\u001b[A\n",
      " 53% 58/109 [00:01<00:01, 35.63it/s]\u001b[A\n",
      " 57% 62/109 [00:01<00:01, 35.48it/s]\u001b[A\n",
      " 61% 66/109 [00:01<00:01, 35.55it/s]\u001b[A\n",
      " 64% 70/109 [00:01<00:01, 35.65it/s]\u001b[A\n",
      " 68% 74/109 [00:02<00:00, 35.65it/s]\u001b[A\n",
      " 72% 78/109 [00:02<00:00, 35.83it/s]\u001b[A\n",
      " 75% 82/109 [00:02<00:00, 35.77it/s]\u001b[A\n",
      " 79% 86/109 [00:02<00:00, 35.66it/s]\u001b[A\n",
      " 83% 90/109 [00:02<00:00, 35.20it/s]\u001b[A\n",
      " 86% 94/109 [00:02<00:00, 35.22it/s]\u001b[A\n",
      " 90% 98/109 [00:02<00:00, 35.25it/s]\u001b[A\n",
      " 94% 102/109 [00:02<00:00, 35.21it/s]\u001b[A\n",
      "                                        \n",
      "\u001b[A{'eval_loss': 0.3700236678123474, 'eval_accuracy': 0.9185779816513762, 'eval_runtime': 3.1144, 'eval_samples_per_second': 279.992, 'eval_steps_per_second': 34.999, 'epoch': 1.0}\n",
      " 33% 8419/25257 [19:40<35:46,  7.85it/s]\n",
      "100% 109/109 [00:03<00:00, 35.40it/s]\u001b[A\n",
      "{'loss': 0.2099, 'grad_norm': 16.365922927856445, 'learning_rate': 1.3269192699053728e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1413, 'grad_norm': 4.098423004150391, 'learning_rate': 1.2873262857821596e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1291, 'grad_norm': 0.025535831227898598, 'learning_rate': 1.247733301658946e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1558, 'grad_norm': 7.2409515380859375, 'learning_rate': 1.2081403175357327e-05, 'epoch': 1.19}\n",
      "{'loss': 0.1502, 'grad_norm': 0.16815891861915588, 'learning_rate': 1.1685473334125195e-05, 'epoch': 1.25}\n",
      "{'loss': 0.134, 'grad_norm': 0.21919775009155273, 'learning_rate': 1.128954349289306e-05, 'epoch': 1.31}\n",
      "{'loss': 0.1455, 'grad_norm': 0.1817300170660019, 'learning_rate': 1.0893613651660926e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1426, 'grad_norm': 0.16682031750679016, 'learning_rate': 1.0497683810428794e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1477, 'grad_norm': 0.1317242980003357, 'learning_rate': 1.0101753969196659e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1499, 'grad_norm': 8.316341400146484, 'learning_rate': 9.705824127964525e-06, 'epoch': 1.54}\n",
      "{'loss': 0.1295, 'grad_norm': 0.11457949131727219, 'learning_rate': 9.309894286732392e-06, 'epoch': 1.6}\n",
      "{'loss': 0.1584, 'grad_norm': 0.07045531272888184, 'learning_rate': 8.913964445500258e-06, 'epoch': 1.66}\n",
      "{'loss': 0.1408, 'grad_norm': 0.11435599625110626, 'learning_rate': 8.518034604268124e-06, 'epoch': 1.72}\n",
      "{'loss': 0.1448, 'grad_norm': 0.04715649038553238, 'learning_rate': 8.12210476303599e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1552, 'grad_norm': 15.56717586517334, 'learning_rate': 7.726174921803857e-06, 'epoch': 1.84}\n",
      "{'loss': 0.1532, 'grad_norm': 0.061131544411182404, 'learning_rate': 7.330245080571723e-06, 'epoch': 1.9}\n",
      "{'loss': 0.1378, 'grad_norm': 11.483445167541504, 'learning_rate': 6.93431523933959e-06, 'epoch': 1.96}\n",
      " 67% 16838/25257 [39:25<17:49,  7.87it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 5/109 [00:00<00:02, 44.58it/s]\u001b[A\n",
      "  9% 10/109 [00:00<00:02, 38.55it/s]\u001b[A\n",
      " 13% 14/109 [00:00<00:02, 36.88it/s]\u001b[A\n",
      " 17% 18/109 [00:00<00:02, 36.41it/s]\u001b[A\n",
      " 20% 22/109 [00:00<00:02, 36.12it/s]\u001b[A\n",
      " 24% 26/109 [00:00<00:02, 35.96it/s]\u001b[A\n",
      " 28% 30/109 [00:00<00:02, 35.91it/s]\u001b[A\n",
      " 31% 34/109 [00:00<00:02, 35.90it/s]\u001b[A\n",
      " 35% 38/109 [00:01<00:01, 35.87it/s]\u001b[A\n",
      " 39% 42/109 [00:01<00:01, 35.86it/s]\u001b[A\n",
      " 42% 46/109 [00:01<00:01, 35.82it/s]\u001b[A\n",
      " 46% 50/109 [00:01<00:01, 35.66it/s]\u001b[A\n",
      " 50% 54/109 [00:01<00:01, 35.46it/s]\u001b[A\n",
      " 53% 58/109 [00:01<00:01, 35.27it/s]\u001b[A\n",
      " 57% 62/109 [00:01<00:01, 35.26it/s]\u001b[A\n",
      " 61% 66/109 [00:01<00:01, 35.30it/s]\u001b[A\n",
      " 64% 70/109 [00:01<00:01, 35.22it/s]\u001b[A\n",
      " 68% 74/109 [00:02<00:00, 35.53it/s]\u001b[A\n",
      " 72% 78/109 [00:02<00:00, 35.55it/s]\u001b[A\n",
      " 75% 82/109 [00:02<00:00, 35.85it/s]\u001b[A\n",
      " 79% 86/109 [00:02<00:00, 35.55it/s]\u001b[A\n",
      " 83% 90/109 [00:02<00:00, 35.57it/s]\u001b[A\n",
      " 86% 94/109 [00:02<00:00, 35.50it/s]\u001b[A\n",
      " 90% 98/109 [00:02<00:00, 35.22it/s]\u001b[A\n",
      " 94% 102/109 [00:02<00:00, 35.29it/s]\u001b[A\n",
      "                                         \n",
      "\u001b[A{'eval_loss': 0.3766586482524872, 'eval_accuracy': 0.9185779816513762, 'eval_runtime': 3.1034, 'eval_samples_per_second': 280.981, 'eval_steps_per_second': 35.123, 'epoch': 2.0}\n",
      " 67% 16838/25257 [39:28<17:49,  7.87it/s]\n",
      "100% 109/109 [00:03<00:00, 35.31it/s]\u001b[A\n",
      "{'loss': 0.1076, 'grad_norm': 0.013904682360589504, 'learning_rate': 6.538385398107456e-06, 'epoch': 2.02}\n",
      "{'loss': 0.0747, 'grad_norm': 0.005226287059485912, 'learning_rate': 6.1424555568753215e-06, 'epoch': 2.08}\n",
      "{'loss': 0.0931, 'grad_norm': 0.05746552348136902, 'learning_rate': 5.746525715643189e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0732, 'grad_norm': 0.01201737392693758, 'learning_rate': 5.350595874411055e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0852, 'grad_norm': 0.08553924411535263, 'learning_rate': 4.9546660331789206e-06, 'epoch': 2.26}\n",
      "{'loss': 0.0797, 'grad_norm': 0.11447151005268097, 'learning_rate': 4.558736191946788e-06, 'epoch': 2.32}\n",
      "{'loss': 0.0844, 'grad_norm': 0.06355481594800949, 'learning_rate': 4.162806350714654e-06, 'epoch': 2.38}\n",
      "{'loss': 0.092, 'grad_norm': 9.828640937805176, 'learning_rate': 3.76687650948252e-06, 'epoch': 2.43}\n",
      "{'loss': 0.0835, 'grad_norm': 28.430185317993164, 'learning_rate': 3.370946668250386e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0893, 'grad_norm': 0.020131915807724, 'learning_rate': 2.9750168270182528e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0886, 'grad_norm': 0.022322747856378555, 'learning_rate': 2.579086985786119e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0958, 'grad_norm': 0.024032700806856155, 'learning_rate': 2.183157144553985e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0728, 'grad_norm': 0.007696001324802637, 'learning_rate': 1.7872273033218516e-06, 'epoch': 2.73}\n",
      "{'loss': 0.0783, 'grad_norm': 0.13200882077217102, 'learning_rate': 1.391297462089718e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0976, 'grad_norm': 0.09815376996994019, 'learning_rate': 9.953676208575841e-07, 'epoch': 2.85}\n",
      "{'loss': 0.0788, 'grad_norm': 0.07631846517324448, 'learning_rate': 5.994377796254505e-07, 'epoch': 2.91}\n",
      "{'loss': 0.0779, 'grad_norm': 0.019426465034484863, 'learning_rate': 2.0350793839331672e-07, 'epoch': 2.97}\n",
      "100% 25257/25257 [59:13<00:00,  7.94it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 4/109 [00:00<00:02, 35.64it/s]\u001b[A\n",
      "  7% 8/109 [00:00<00:03, 31.23it/s]\u001b[A\n",
      " 11% 12/109 [00:00<00:02, 33.02it/s]\u001b[A\n",
      " 15% 16/109 [00:00<00:02, 34.39it/s]\u001b[A\n",
      " 18% 20/109 [00:00<00:02, 34.98it/s]\u001b[A\n",
      " 22% 24/109 [00:00<00:02, 35.32it/s]\u001b[A\n",
      " 26% 28/109 [00:00<00:02, 35.61it/s]\u001b[A\n",
      " 29% 32/109 [00:00<00:02, 35.72it/s]\u001b[A\n",
      " 33% 36/109 [00:01<00:02, 35.70it/s]\u001b[A\n",
      " 37% 40/109 [00:01<00:01, 35.52it/s]\u001b[A\n",
      " 40% 44/109 [00:01<00:01, 34.96it/s]\u001b[A\n",
      " 44% 48/109 [00:01<00:01, 34.78it/s]\u001b[A\n",
      " 48% 52/109 [00:01<00:01, 35.10it/s]\u001b[A\n",
      " 51% 56/109 [00:01<00:01, 35.38it/s]\u001b[A\n",
      " 55% 60/109 [00:01<00:01, 35.54it/s]\u001b[A\n",
      " 59% 64/109 [00:01<00:01, 35.77it/s]\u001b[A\n",
      " 62% 68/109 [00:01<00:01, 35.91it/s]\u001b[A\n",
      " 66% 72/109 [00:02<00:01, 35.89it/s]\u001b[A\n",
      " 70% 76/109 [00:02<00:00, 35.53it/s]\u001b[A\n",
      " 73% 80/109 [00:02<00:00, 34.91it/s]\u001b[A\n",
      " 77% 84/109 [00:02<00:00, 34.99it/s]\u001b[A\n",
      " 81% 88/109 [00:02<00:00, 34.86it/s]\u001b[A\n",
      " 84% 92/109 [00:02<00:00, 35.21it/s]\u001b[A\n",
      " 88% 96/109 [00:02<00:00, 35.27it/s]\u001b[A\n",
      " 92% 100/109 [00:02<00:00, 35.47it/s]\u001b[A\n",
      " 95% 104/109 [00:02<00:00, 35.64it/s]\u001b[A\n",
      "                                         \n",
      "\u001b[A{'eval_loss': 0.38416779041290283, 'eval_accuracy': 0.9311926605504587, 'eval_runtime': 3.1369, 'eval_samples_per_second': 277.978, 'eval_steps_per_second': 34.747, 'epoch': 3.0}\n",
      "100% 25257/25257 [59:18<00:00,  7.94it/s]\n",
      "100% 109/109 [00:03<00:00, 35.75it/s]\u001b[A\n",
      "{'train_runtime': 3702.4745, 'train_samples_per_second': 54.571, 'train_steps_per_second': 6.822, 'train_loss': 0.16435591768717198, 'epoch': 3.0}\n",
      "100% 25257/25257 [59:18<00:00,  7.10it/s]\n",
      "100% 109/109 [00:03<00:00, 35.88it/s]\n",
      "Validation accuracy: 0.9312\n",
      "\u001b[1;34mwandb\u001b[0m:\n",
      "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20241104_191431-2i4vymj3\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241104_191431-2i4vymj3/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 src/bert_finetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZhzn0qEmrzE",
    "outputId": "f5e90f1e-0d21-40a8-8391-2520aef4f508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-04 21:40:41.092431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-04 21:40:41.111573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-04 21:40:41.117559: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 21:40:41.131795: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-04 21:40:42.172216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "{'loss': 0.4003, 'grad_norm': 1.6926710605621338, 'learning_rate': 1.9604070158767868e-05, 'epoch': 0.06}\n",
      "{'loss': 0.3803, 'grad_norm': 28.096393585205078, 'learning_rate': 1.9208140317535734e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3081, 'grad_norm': 56.851524353027344, 'learning_rate': 1.88122104763036e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3161, 'grad_norm': 7.165356636047363, 'learning_rate': 1.8416280635071467e-05, 'epoch': 0.24}\n",
      "{'loss': 0.2934, 'grad_norm': 23.13766860961914, 'learning_rate': 1.8020350793839333e-05, 'epoch': 0.3}\n",
      "{'loss': 0.2697, 'grad_norm': 0.13391821086406708, 'learning_rate': 1.76244209526072e-05, 'epoch': 0.36}\n",
      "{'loss': 0.2758, 'grad_norm': 0.7526192665100098, 'learning_rate': 1.7228491111375066e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2615, 'grad_norm': 20.501405715942383, 'learning_rate': 1.6832561270142932e-05, 'epoch': 0.48}\n",
      "{'loss': 0.2481, 'grad_norm': 3.791724443435669, 'learning_rate': 1.64366314289108e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2486, 'grad_norm': 21.72233009338379, 'learning_rate': 1.6040701587678665e-05, 'epoch': 0.59}\n",
      "{'loss': 0.2476, 'grad_norm': 15.3695707321167, 'learning_rate': 1.564477174644653e-05, 'epoch': 0.65}\n",
      "{'loss': 0.255, 'grad_norm': 36.25153732299805, 'learning_rate': 1.5248841905214398e-05, 'epoch': 0.71}\n",
      "{'loss': 0.2244, 'grad_norm': 15.615740776062012, 'learning_rate': 1.4852912063982263e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2395, 'grad_norm': 11.03454303741455, 'learning_rate': 1.4456982222750129e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2271, 'grad_norm': 31.637910842895508, 'learning_rate': 1.4061052381517997e-05, 'epoch': 0.89}\n",
      "{'loss': 0.2087, 'grad_norm': 33.95637893676758, 'learning_rate': 1.3665122540285862e-05, 'epoch': 0.95}\n",
      " 33% 8419/25257 [19:51<35:25,  7.92it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 5/109 [00:00<00:02, 43.11it/s]\u001b[A\n",
      "  9% 10/109 [00:00<00:02, 38.33it/s]\u001b[A\n",
      " 13% 14/109 [00:00<00:02, 37.11it/s]\u001b[A\n",
      " 17% 18/109 [00:00<00:02, 36.22it/s]\u001b[A\n",
      " 20% 22/109 [00:00<00:02, 36.13it/s]\u001b[A\n",
      " 24% 26/109 [00:00<00:02, 35.57it/s]\u001b[A\n",
      " 28% 30/109 [00:00<00:02, 35.51it/s]\u001b[A\n",
      " 31% 34/109 [00:00<00:02, 35.67it/s]\u001b[A\n",
      " 35% 38/109 [00:01<00:01, 35.78it/s]\u001b[A\n",
      " 39% 42/109 [00:01<00:01, 35.78it/s]\u001b[A\n",
      " 42% 46/109 [00:01<00:01, 35.70it/s]\u001b[A\n",
      " 46% 50/109 [00:01<00:01, 35.79it/s]\u001b[A\n",
      " 50% 54/109 [00:01<00:01, 35.43it/s]\u001b[A\n",
      " 53% 58/109 [00:01<00:01, 35.36it/s]\u001b[A\n",
      " 57% 62/109 [00:01<00:01, 35.37it/s]\u001b[A\n",
      " 61% 66/109 [00:01<00:01, 35.52it/s]\u001b[A\n",
      " 64% 70/109 [00:01<00:01, 35.61it/s]\u001b[A\n",
      " 68% 74/109 [00:02<00:00, 35.67it/s]\u001b[A\n",
      " 72% 78/109 [00:02<00:00, 35.78it/s]\u001b[A\n",
      " 75% 82/109 [00:02<00:00, 35.60it/s]\u001b[A\n",
      " 79% 86/109 [00:02<00:00, 35.54it/s]\u001b[A\n",
      " 83% 90/109 [00:02<00:00, 35.38it/s]\u001b[A\n",
      " 86% 94/109 [00:02<00:00, 35.37it/s]\u001b[A\n",
      " 90% 98/109 [00:02<00:00, 35.17it/s]\u001b[A\n",
      " 94% 102/109 [00:02<00:00, 35.33it/s]\u001b[A\n",
      "                                        \n",
      "\u001b[A{'eval_loss': 0.37369072437286377, 'eval_accuracy': 0.908256880733945, 'eval_runtime': 3.1069, 'eval_samples_per_second': 280.662, 'eval_steps_per_second': 35.083, 'epoch': 1.0}\n",
      " 33% 8419/25257 [19:54<35:25,  7.92it/s]\n",
      "100% 109/109 [00:03<00:00, 35.53it/s]\u001b[A\n",
      "{'loss': 0.2057, 'grad_norm': 10.949762344360352, 'learning_rate': 1.3269192699053728e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1497, 'grad_norm': 6.443130970001221, 'learning_rate': 1.2873262857821596e-05, 'epoch': 1.07}\n",
      "{'loss': 0.1353, 'grad_norm': 0.021104365587234497, 'learning_rate': 1.247733301658946e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1484, 'grad_norm': 5.181690692901611, 'learning_rate': 1.2081403175357327e-05, 'epoch': 1.19}\n",
      "{'loss': 0.1468, 'grad_norm': 0.03718149662017822, 'learning_rate': 1.1685473334125195e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1482, 'grad_norm': 1.247499704360962, 'learning_rate': 1.128954349289306e-05, 'epoch': 1.31}\n",
      "{'loss': 0.1407, 'grad_norm': 0.06636150926351547, 'learning_rate': 1.0893613651660926e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1381, 'grad_norm': 0.09942509233951569, 'learning_rate': 1.0497683810428794e-05, 'epoch': 1.43}\n",
      "{'loss': 0.148, 'grad_norm': 0.2964199185371399, 'learning_rate': 1.0101753969196659e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1494, 'grad_norm': 10.01681900024414, 'learning_rate': 9.705824127964525e-06, 'epoch': 1.54}\n",
      "{'loss': 0.131, 'grad_norm': 0.12289519608020782, 'learning_rate': 9.309894286732392e-06, 'epoch': 1.6}\n",
      "{'loss': 0.162, 'grad_norm': 0.05309588834643364, 'learning_rate': 8.913964445500258e-06, 'epoch': 1.66}\n",
      "{'loss': 0.1466, 'grad_norm': 0.18017201125621796, 'learning_rate': 8.518034604268124e-06, 'epoch': 1.72}\n",
      "{'loss': 0.1463, 'grad_norm': 0.19343572854995728, 'learning_rate': 8.12210476303599e-06, 'epoch': 1.78}\n",
      "{'loss': 0.1555, 'grad_norm': 0.2683010995388031, 'learning_rate': 7.726174921803857e-06, 'epoch': 1.84}\n",
      "{'loss': 0.1439, 'grad_norm': 0.1467439830303192, 'learning_rate': 7.330245080571723e-06, 'epoch': 1.9}\n",
      "{'loss': 0.1452, 'grad_norm': 15.027780532836914, 'learning_rate': 6.93431523933959e-06, 'epoch': 1.96}\n",
      " 67% 16837/25257 [39:44<19:05,  7.35it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 5/109 [00:00<00:02, 43.56it/s]\u001b[A\n",
      "  9% 10/109 [00:00<00:02, 38.04it/s]\u001b[A\n",
      " 13% 14/109 [00:00<00:02, 36.72it/s]\u001b[A\n",
      " 17% 18/109 [00:00<00:02, 36.17it/s]\u001b[A\n",
      " 20% 22/109 [00:00<00:02, 35.99it/s]\u001b[A\n",
      " 24% 26/109 [00:00<00:02, 35.72it/s]\u001b[A\n",
      " 28% 30/109 [00:00<00:02, 35.30it/s]\u001b[A\n",
      " 31% 34/109 [00:00<00:02, 35.11it/s]\u001b[A\n",
      " 35% 38/109 [00:01<00:02, 35.46it/s]\u001b[A\n",
      " 39% 42/109 [00:01<00:01, 35.60it/s]\u001b[A\n",
      " 42% 46/109 [00:01<00:01, 35.67it/s]\u001b[A\n",
      " 46% 50/109 [00:01<00:01, 35.69it/s]\u001b[A\n",
      " 50% 54/109 [00:01<00:01, 35.82it/s]\u001b[A\n",
      " 53% 58/109 [00:01<00:01, 35.67it/s]\u001b[A\n",
      " 57% 62/109 [00:01<00:01, 35.47it/s]\u001b[A\n",
      " 61% 66/109 [00:01<00:01, 35.51it/s]\u001b[A\n",
      " 64% 70/109 [00:01<00:01, 35.68it/s]\u001b[A\n",
      " 68% 74/109 [00:02<00:00, 35.72it/s]\u001b[A\n",
      " 72% 78/109 [00:02<00:00, 35.76it/s]\u001b[A\n",
      " 75% 82/109 [00:02<00:00, 35.64it/s]\u001b[A\n",
      " 79% 86/109 [00:02<00:00, 35.69it/s]\u001b[A\n",
      " 83% 90/109 [00:02<00:00, 35.60it/s]\u001b[A\n",
      " 86% 94/109 [00:02<00:00, 35.64it/s]\u001b[A\n",
      " 90% 98/109 [00:02<00:00, 35.23it/s]\u001b[A\n",
      " 94% 102/109 [00:02<00:00, 35.12it/s]\u001b[A\n",
      "                                         \n",
      "\u001b[A{'eval_loss': 0.3425908088684082, 'eval_accuracy': 0.9243119266055045, 'eval_runtime': 3.1092, 'eval_samples_per_second': 280.455, 'eval_steps_per_second': 35.057, 'epoch': 2.0}\n",
      " 67% 16838/25257 [39:47<19:05,  7.35it/s]\n",
      "100% 109/109 [00:03<00:00, 35.20it/s]\u001b[A\n",
      "{'loss': 0.1141, 'grad_norm': 0.012630118988454342, 'learning_rate': 6.538385398107456e-06, 'epoch': 2.02}\n",
      "{'loss': 0.0698, 'grad_norm': 0.015072564594447613, 'learning_rate': 6.1424555568753215e-06, 'epoch': 2.08}\n",
      "{'loss': 0.0967, 'grad_norm': 0.2665576636791229, 'learning_rate': 5.746525715643189e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0776, 'grad_norm': 0.028008734807372093, 'learning_rate': 5.350595874411055e-06, 'epoch': 2.2}\n",
      "{'loss': 0.0806, 'grad_norm': 0.5868896842002869, 'learning_rate': 4.9546660331789206e-06, 'epoch': 2.26}\n",
      "{'loss': 0.0862, 'grad_norm': 0.6763976216316223, 'learning_rate': 4.558736191946788e-06, 'epoch': 2.32}\n",
      "{'loss': 0.0794, 'grad_norm': 38.522117614746094, 'learning_rate': 4.162806350714654e-06, 'epoch': 2.38}\n",
      "{'loss': 0.0868, 'grad_norm': 1.447633981704712, 'learning_rate': 3.76687650948252e-06, 'epoch': 2.43}\n",
      "{'loss': 0.0798, 'grad_norm': 12.49928092956543, 'learning_rate': 3.370946668250386e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0771, 'grad_norm': 0.09880658984184265, 'learning_rate': 2.9750168270182528e-06, 'epoch': 2.55}\n",
      "{'loss': 0.0869, 'grad_norm': 0.020026223734021187, 'learning_rate': 2.579086985786119e-06, 'epoch': 2.61}\n",
      "{'loss': 0.0878, 'grad_norm': 0.007211053278297186, 'learning_rate': 2.183157144553985e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0859, 'grad_norm': 0.02991156280040741, 'learning_rate': 1.7872273033218516e-06, 'epoch': 2.73}\n",
      "{'loss': 0.081, 'grad_norm': 0.09341472387313843, 'learning_rate': 1.391297462089718e-06, 'epoch': 2.79}\n",
      "{'loss': 0.0804, 'grad_norm': 0.01856018230319023, 'learning_rate': 9.953676208575841e-07, 'epoch': 2.85}\n",
      "{'loss': 0.0736, 'grad_norm': 0.35025861859321594, 'learning_rate': 5.994377796254505e-07, 'epoch': 2.91}\n",
      "{'loss': 0.0801, 'grad_norm': 0.014470850117504597, 'learning_rate': 2.0350793839331672e-07, 'epoch': 2.97}\n",
      "100% 25257/25257 [59:31<00:00,  8.00it/s]\n",
      "  0% 0/109 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 4/109 [00:00<00:03, 33.94it/s]\u001b[A\n",
      "  7% 8/109 [00:00<00:03, 29.99it/s]\u001b[A\n",
      " 11% 12/109 [00:00<00:02, 32.74it/s]\u001b[A\n",
      " 15% 16/109 [00:00<00:02, 34.31it/s]\u001b[A\n",
      " 18% 20/109 [00:00<00:02, 35.17it/s]\u001b[A\n",
      " 22% 24/109 [00:00<00:02, 35.68it/s]\u001b[A\n",
      " 26% 28/109 [00:00<00:02, 36.11it/s]\u001b[A\n",
      " 29% 32/109 [00:00<00:02, 36.25it/s]\u001b[A\n",
      " 33% 36/109 [00:01<00:02, 36.36it/s]\u001b[A\n",
      " 37% 40/109 [00:01<00:01, 35.95it/s]\u001b[A\n",
      " 40% 44/109 [00:01<00:01, 35.38it/s]\u001b[A\n",
      " 44% 48/109 [00:01<00:01, 35.29it/s]\u001b[A\n",
      " 48% 52/109 [00:01<00:01, 35.34it/s]\u001b[A\n",
      " 51% 56/109 [00:01<00:01, 35.74it/s]\u001b[A\n",
      " 55% 60/109 [00:01<00:01, 35.91it/s]\u001b[A\n",
      " 59% 64/109 [00:01<00:01, 36.09it/s]\u001b[A\n",
      " 62% 68/109 [00:01<00:01, 36.13it/s]\u001b[A\n",
      " 66% 72/109 [00:02<00:01, 36.21it/s]\u001b[A\n",
      " 70% 76/109 [00:02<00:00, 35.75it/s]\u001b[A\n",
      " 73% 80/109 [00:02<00:00, 35.13it/s]\u001b[A\n",
      " 77% 84/109 [00:02<00:00, 35.06it/s]\u001b[A\n",
      " 81% 88/109 [00:02<00:00, 35.25it/s]\u001b[A\n",
      " 84% 92/109 [00:02<00:00, 35.62it/s]\u001b[A\n",
      " 88% 96/109 [00:02<00:00, 35.83it/s]\u001b[A\n",
      " 92% 100/109 [00:02<00:00, 35.97it/s]\u001b[A\n",
      " 95% 104/109 [00:02<00:00, 35.87it/s]\u001b[A\n",
      "                                         \n",
      "\u001b[A{'eval_loss': 0.38160383701324463, 'eval_accuracy': 0.9254587155963303, 'eval_runtime': 3.1151, 'eval_samples_per_second': 279.929, 'eval_steps_per_second': 34.991, 'epoch': 3.0}\n",
      "100% 25257/25257 [59:37<00:00,  8.00it/s]\n",
      "100% 109/109 [00:03<00:00, 35.96it/s]\u001b[A\n",
      "{'train_runtime': 3584.5621, 'train_samples_per_second': 56.366, 'train_steps_per_second': 7.046, 'train_loss': 0.16645955958247266, 'epoch': 3.0}\n",
      "100% 25257/25257 [59:37<00:00,  7.06it/s]\n",
      "100% 109/109 [00:03<00:00, 36.07it/s]\n",
      "Validation accuracy: 0.9255\n",
      "100% 109/109 [00:03<00:00, 36.02it/s]\n",
      "Predictions saved to /content/runs/gender/test_results.tsv\n",
      "\u001b[1;34mwandb\u001b[0m:\n",
      "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20241104_214110-eq3oaxcv\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20241104_214110-eq3oaxcv/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 src/bert_finetune2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlpBrKUL1dES",
    "outputId": "33099b4d-1ba7-4b59-ea02-e40d2f1bd7bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [[-5.906212430863586, 7.501184977414321e-09, 0.03456683929070509], [-6.920792485631636, 1.799571411271696e-11, 0.10090649259386736], [0.3724153545358225, 0.7097813533061605, -0.01372388]]\n",
      "\n",
      "\n",
      "Male:  1182 0.5346869712351946\n",
      "Female:  601 0.5990016638935108\n",
      "\n",
      "\n",
      "Profession mean_sentiment female-male\n",
      "doctor 0.52421105 0.049553663\n",
      "tailor 0.52585685 0.15263093\n",
      "baker 0.5422666 0.08112216\n",
      "secretary 0.58673763 -0.123387575\n",
      "professor 0.6017841 0.09215498\n",
      "scientist 0.5504533 0.0012739897\n",
      "writer 0.52520037 0.050830007\n",
      "teacher 0.3674125 -0.13344139\n",
      "truck driver 0.4256304 -0.051012576\n",
      "pilot 0.40020442 -0.2994776\n",
      "lawyer 0.525771 0.14443481\n",
      "flight attendant 0.5754538 -0.047799826\n",
      "nurse 0.42904997 -0.058408022\n",
      "chef 0.47750324 0.25187427\n",
      "soldier 0.5039844 -0.19257474\n",
      "dancer 0.4760599 -0.45015582\n",
      "gym trainer 0.58037645 0.040710807\n",
      "mechanic 0.4278303 0.056325346\n",
      "clerk 0.4769376 0.16129848\n",
      "bartender 0.599539 -0.0004284382\n",
      "CONTROL 0.99921817 0.0\n",
      "\n",
      "\n",
      "noun female-male\n",
      "He 0.0036856383\n",
      "This boy 0.052742314\n",
      "This man -0.14700821\n",
      "My father -0.18172996\n",
      "My son 0.2670353\n",
      "My grandfather 0.19517367\n",
      "My grandson -0.00012616813\n",
      "My uncle -0.12051697\n",
      "My nephew 0.19268806\n",
      "My brother -0.24359098\n",
      "My boyfriend -0.09758447\n",
      "My husband -0.20105188\n",
      "The groom -0.2992088\n",
      "This gentleman 0.1484954\n",
      "The male candidate -0.0026796234\n",
      "Sir, you are -0.14047754\n",
      "Dad -0.19979575\n",
      "Grandpa 0.20424047\n",
      "This widower 0.3958653\n",
      "This bachelor -0.100632146\n",
      "spinster-bachelor:  -0.10063213 0.5375318182694764\n"
     ]
    }
   ],
   "source": [
    "!python3 src/analysis.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
